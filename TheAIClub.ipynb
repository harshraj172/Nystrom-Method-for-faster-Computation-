{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TheAIClub.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgIRFEpR3-aO"
      },
      "source": [
        "#Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "31U4UsqaKeMR",
        "outputId": "c228e82e-1911-47b9-fcfc-39d698863ecb"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from tqdm import tqdm\r\n",
        "import string\r\n",
        "tqdm.pandas(desc=\"progress-bar\")\r\n",
        "from gensim.models import Doc2Vec\r\n",
        "from sklearn import utils\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import gensim\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from gensim.models.doc2vec import TaggedDocument\r\n",
        "import re\r\n",
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "#Reading the data\r\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/train.csv\", sep=',', na_values=['nan', '?'], \r\n",
        "                 names=['ClassID', 'Title', 'Body'])\r\n",
        "#Combining the text and body into a single dataframe caleld text \r\n",
        "df['Text'] = df['Title'].str.cat(df['Body'], sep =\" \") \r\n",
        "df.drop(['Title', 'Body'], axis=1, inplace=True)\r\n",
        "\r\n",
        "!python -m pip install pyspellchecker\r\n",
        "!pip install num2words\r\n",
        "!pip install word2vec\r\n",
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "\r\n",
        "from num2words import num2words \r\n",
        "from nltk.stem import WordNetLemmatizer \r\n",
        "from nltk.stem import PorterStemmer \r\n",
        "from nltk.corpus import stopwords\r\n",
        "import operator\r\n",
        "from spellchecker import SpellChecker\r\n",
        "\r\n",
        "#Remove URLs\r\n",
        "def remove_urls(data):\r\n",
        "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\r\n",
        "    return url_pattern.sub(r'', data)\r\n",
        "\r\n",
        "#Correcting spellings\r\n",
        "def correct_spellings(data):\r\n",
        "    spell = SpellChecker()\r\n",
        "    corrected_text = []\r\n",
        "    misspelled_words = spell.unknown(data.split())\r\n",
        "    for word in data.split():\r\n",
        "        if word in misspelled_words:\r\n",
        "            corrected_text.append(spell.correction(word))\r\n",
        "        else:\r\n",
        "            corrected_text.append(word)\r\n",
        "    return \" \".join(corrected_text)\r\n",
        "\r\n",
        "def convert_lower_case(data):\r\n",
        "  return str(data).lower()\r\n",
        "\r\n",
        "#Removing the punctuations\r\n",
        "def remove_punctuation(data):\r\n",
        "  symbols = string.punctuation\r\n",
        "  for symbol in symbols:\r\n",
        "    data = str(data).replace(symbol, '')\r\n",
        "  return data\r\n",
        "\r\n",
        "#Remove single words a they are meaningless\r\n",
        "def remove_single_characters(data):\r\n",
        "  new_data = \"\"\r\n",
        "  for word in data.split():\r\n",
        "    if len(word) > 1:\r\n",
        "      new_data = new_data + \" \" + word\r\n",
        "  return new_data\r\n",
        "\r\n",
        "#Convert numbers into words\r\n",
        "def convert_numbers(data):\r\n",
        "  new_data = \"\"\r\n",
        "  for word in data.split():\r\n",
        "    if(word.isnumeric()):\r\n",
        "      word = num2words(word)\r\n",
        "    new_data = new_data + \" \" + word\r\n",
        "  return new_data\r\n",
        "\r\n",
        "#Stemming the dataset\r\n",
        "def stemming(data):\r\n",
        "  stemmer = PorterStemmer()\r\n",
        "  new_data = \"\"\r\n",
        "  for word in data.split():\r\n",
        "    word = stemmer.stem(word)\r\n",
        "    new_data = new_data + \" \" + word\r\n",
        "  return new_data\r\n",
        "\r\n",
        "#Lemmatizing the dataset\r\n",
        "def lemmatizer(data):\r\n",
        "  lemmatizer = WordNetLemmatizer()\r\n",
        "  new_data = \"\"\r\n",
        "  for word in data.split():\r\n",
        "    word = lemmatizer.lemmatize(word)\r\n",
        "    new_data = new_data + \" \" + word\r\n",
        "  return new_data\r\n",
        "\r\n",
        "#Preprocessing-01\r\n",
        "def preprocessing1(dataset):\r\n",
        "  new_dataset = []\r\n",
        "  for data in dataset:\r\n",
        "    #data = remove_urls(data)\r\n",
        "    #data = correct_spellings(data)\r\n",
        "    data = convert_lower_case(data)\r\n",
        "    data = remove_punctuation(data)\r\n",
        "    data = remove_single_characters(data)\r\n",
        "    data = convert_numbers(data)\r\n",
        "    data = remove_punctuation(data)\r\n",
        "    data = convert_numbers(data)\r\n",
        "    new_dataset.append(data)\r\n",
        "  return new_dataset\r\n",
        "\r\n",
        "df['Text'] = preprocessing1(df['Text'])\r\n",
        "##################################################\r\n",
        "#Preprocessing for removing stopwords\r\n",
        "\r\n",
        "#Building a list of stopwords from the data using Zipf' Law\r\n",
        "def buildstoplist(trainingdata):\r\n",
        "    index = {}\r\n",
        "    wordcount = 0\r\n",
        "    wordprob = {}\r\n",
        "    stop_words = list(stopwords.words('english')) #Calling predefined stopwords list from nltk\r\n",
        "    for i in trainingdata:\r\n",
        "        for word in i[0].split():\r\n",
        "            word = re.sub('[^a-zA-Z0-9 \\n\\.]', '', word)\r\n",
        "            if word != '':\r\n",
        "                wordcount += 1\r\n",
        "                if word not in index:\r\n",
        "                    index[word] = 1\r\n",
        "                else:\r\n",
        "                    index[word] += 1\r\n",
        "    \r\n",
        "    for word in index:\r\n",
        "        wordprob[word] = round(float(index[word])/wordcount*100,4) #Calculating the probability\r\n",
        "        \r\n",
        "    stoplist = sorted(wordprob, key=operator.itemgetter(1) ,reverse=True)[:25000] #Storing top 25000 most frequent words of the data\r\n",
        "    \r\n",
        "    for i in stoplist:\r\n",
        "        stop_words.append(i[0]) #Making a list od stopwords\r\n",
        "    stop_words.append('reuters')\r\n",
        "    return stop_words\r\n",
        "  \r\n",
        "stopwords = buildstoplist(df['Text'])\r\n",
        "\r\n",
        "#Removing stopwords from the dataset\r\n",
        "def remove_stopwords(data):\r\n",
        "  new_data = \"\"\r\n",
        "  for word in data.split():\r\n",
        "    if word not in stopwords:\r\n",
        "      new_data = new_data + \" \" + word\r\n",
        "  return new_data\r\n",
        "\r\n",
        "#Preprocessing-02\r\n",
        "def preprocessing2(dataset):\r\n",
        "  new_dataset = []\r\n",
        "  for data in dataset:\r\n",
        "    #data = remove_urls(data)\r\n",
        "    #data = correct_spellings(data)\r\n",
        "    data = remove_stopwords(data)\r\n",
        "    new_dataset.append(data)\r\n",
        "  return new_dataset\r\n",
        "\r\n",
        "df['Text'] = preprocessing2(df['Text'])\r\n",
        "df['Text'].head()\r\n",
        "\r\n",
        "from gensim.models import Word2Vec\r\n",
        "sentences  = []\r\n",
        "#Getting tokens of words\r\n",
        "for sentence in df['Text']:\r\n",
        "  sentences.append(sentence.split())\r\n",
        "\r\n",
        "#Creating a word2vec with vector size of 150\r\n",
        "model = Word2Vec(sentences, size = 150, min_count=1)\r\n",
        "#Calling the vocabulary of model into X\r\n",
        "X = model[model.wv.vocab]\r\n",
        "\r\n",
        "# train autoencoder for classification with with compression in the bottleneck layer\r\n",
        "from sklearn.datasets import make_classification\r\n",
        "from sklearn.preprocessing import MinMaxScaler   \r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.layers import Input\r\n",
        "from tensorflow.keras.layers import Dense\r\n",
        "from tensorflow.keras.layers import LeakyReLU\r\n",
        "from tensorflow.keras.layers import BatchNormalization\r\n",
        "from tensorflow.keras.utils import plot_model\r\n",
        "from matplotlib import pyplot\r\n",
        "# number of input columns\r\n",
        "n_inputs = X.shape[1]\r\n",
        "# split into train test sets\r\n",
        "X_train = X[:80000]\r\n",
        "X_test = X[80000:]\r\n",
        "# scale data\r\n",
        "t = MinMaxScaler()\r\n",
        "t.fit(X_train)\r\n",
        "X_train = t.transform(X_train)\r\n",
        "X_test = t.transform(X_test)\r\n",
        "# define encoder\r\n",
        "visible = Input(shape=(n_inputs,))\r\n",
        "# encoder level 1\r\n",
        "e = Dense(n_inputs*2)(visible)\r\n",
        "e = BatchNormalization()(e)\r\n",
        "e = LeakyReLU()(e)\r\n",
        "# encoder level 2\r\n",
        "e = Dense(n_inputs)(e)\r\n",
        "e = BatchNormalization()(e)\r\n",
        "e = LeakyReLU()(e)\r\n",
        "# bottleneck\r\n",
        "n_bottleneck = round(2.0)\r\n",
        "#float(n_inputs) / 5.0\r\n",
        "bottleneck = Dense(n_bottleneck)(e)\r\n",
        "# define decoder, level 1\r\n",
        "d = Dense(n_inputs)(bottleneck)\r\n",
        "d = BatchNormalization()(d)\r\n",
        "d = LeakyReLU()(d)\r\n",
        "# decoder level 2\r\n",
        "d = Dense(n_inputs*2)(d)\r\n",
        "d = BatchNormalization()(d)\r\n",
        "d = LeakyReLU()(d)\r\n",
        "# output layer\r\n",
        "output = Dense(n_inputs, activation='linear')(d)\r\n",
        "# define autoencoder model\r\n",
        "model = Model(inputs=visible, outputs=output)\r\n",
        "# compile autoencoder model\r\n",
        "model.compile(optimizer='adam', loss='mse')\r\n",
        "# plot the autoencoder\r\n",
        "plot_model(model, 'autoencoder_compress.png', show_shapes=True)\r\n",
        "# fit the autoencoder model to reconstruct input\r\n",
        "history = model.fit(X_train, X_train, epochs=100, batch_size=16, verbose=2, validation_data=(X_test,X_test))\r\n",
        "# plot loss\r\n",
        "pyplot.plot(history.history['loss'], label='train')\r\n",
        "pyplot.plot(history.history['val_loss'], label='test')\r\n",
        "pyplot.legend()\r\n",
        "pyplot.show()\r\n",
        "# define an encoder model (without the decoder)\r\n",
        "encoder = Model(inputs=visible, outputs=bottleneck)\r\n",
        "plot_model(encoder, 'encoder_compress.png', show_shapes=True)\r\n",
        "# save the encoder to file\r\n",
        "encoder.save('encoder.h5')\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "encoder = tf.keras.models.load_model('encoder.h5') #calling the function\r\n",
        "X = encoder.predict(X) #predicting the encoded X\r\n",
        "X.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
            "  from pandas import Panel\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspellchecker in /usr/local/lib/python3.7/dist-packages (0.6.1)\n",
            "Requirement already satisfied: num2words in /usr/local/lib/python3.7/dist-packages (0.5.10)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.7/dist-packages (from num2words) (0.6.2)\n",
            "Requirement already satisfied: word2vec in /usr/local/lib/python3.7/dist-packages (0.11.1)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.7/dist-packages (from word2vec) (1.19.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from word2vec) (1.0.1)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:175: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "5000/5000 - 22s - loss: 0.0033 - val_loss: 0.0016\n",
            "Epoch 2/100\n",
            "5000/5000 - 21s - loss: 0.0011 - val_loss: 0.0113\n",
            "Epoch 3/100\n",
            "5000/5000 - 21s - loss: 8.0664e-04 - val_loss: 6.2269e-04\n",
            "Epoch 4/100\n",
            "5000/5000 - 21s - loss: 6.3956e-04 - val_loss: 2.9405e-04\n",
            "Epoch 5/100\n",
            "5000/5000 - 21s - loss: 5.0530e-04 - val_loss: 5.9208e-05\n",
            "Epoch 6/100\n",
            "5000/5000 - 21s - loss: 4.3624e-04 - val_loss: 0.0011\n",
            "Epoch 7/100\n",
            "5000/5000 - 21s - loss: 4.1129e-04 - val_loss: 8.5951e-05\n",
            "Epoch 8/100\n",
            "5000/5000 - 21s - loss: 4.0116e-04 - val_loss: 3.5357e-05\n",
            "Epoch 9/100\n",
            "5000/5000 - 21s - loss: 3.9413e-04 - val_loss: 1.3022e-05\n",
            "Epoch 10/100\n",
            "5000/5000 - 21s - loss: 3.8846e-04 - val_loss: 1.4833e-05\n",
            "Epoch 11/100\n",
            "5000/5000 - 21s - loss: 3.8560e-04 - val_loss: 3.6293e-05\n",
            "Epoch 12/100\n",
            "5000/5000 - 21s - loss: 3.8123e-04 - val_loss: 4.5200e-05\n",
            "Epoch 13/100\n",
            "5000/5000 - 21s - loss: 3.7979e-04 - val_loss: 1.1751e-05\n",
            "Epoch 14/100\n",
            "5000/5000 - 21s - loss: 3.7653e-04 - val_loss: 2.3745e-05\n",
            "Epoch 15/100\n",
            "5000/5000 - 21s - loss: 3.7453e-04 - val_loss: 1.3796e-05\n",
            "Epoch 16/100\n",
            "5000/5000 - 21s - loss: 3.7354e-04 - val_loss: 6.3150e-05\n",
            "Epoch 17/100\n",
            "5000/5000 - 21s - loss: 3.7148e-04 - val_loss: 1.0355e-04\n",
            "Epoch 18/100\n",
            "5000/5000 - 21s - loss: 3.6970e-04 - val_loss: 1.0300e-05\n",
            "Epoch 19/100\n",
            "5000/5000 - 20s - loss: 3.6874e-04 - val_loss: 1.4334e-05\n",
            "Epoch 20/100\n",
            "5000/5000 - 21s - loss: 3.6779e-04 - val_loss: 5.9858e-05\n",
            "Epoch 21/100\n",
            "5000/5000 - 21s - loss: 3.6737e-04 - val_loss: 4.3190e-05\n",
            "Epoch 22/100\n",
            "5000/5000 - 21s - loss: 3.6518e-04 - val_loss: 1.0807e-05\n",
            "Epoch 23/100\n",
            "5000/5000 - 21s - loss: 3.6461e-04 - val_loss: 1.7149e-05\n",
            "Epoch 24/100\n",
            "5000/5000 - 21s - loss: 3.6443e-04 - val_loss: 1.5017e-05\n",
            "Epoch 25/100\n",
            "5000/5000 - 21s - loss: 3.6323e-04 - val_loss: 4.9627e-05\n",
            "Epoch 26/100\n",
            "5000/5000 - 21s - loss: 3.6177e-04 - val_loss: 2.1377e-05\n",
            "Epoch 27/100\n",
            "5000/5000 - 21s - loss: 3.6072e-04 - val_loss: 1.7446e-05\n",
            "Epoch 28/100\n",
            "5000/5000 - 21s - loss: 3.6119e-04 - val_loss: 1.3524e-05\n",
            "Epoch 29/100\n",
            "5000/5000 - 21s - loss: 3.6006e-04 - val_loss: 9.1575e-06\n",
            "Epoch 30/100\n",
            "5000/5000 - 21s - loss: 3.5980e-04 - val_loss: 2.5273e-05\n",
            "Epoch 31/100\n",
            "5000/5000 - 21s - loss: 3.5838e-04 - val_loss: 2.2683e-05\n",
            "Epoch 32/100\n",
            "5000/5000 - 20s - loss: 3.5769e-04 - val_loss: 1.6318e-04\n",
            "Epoch 33/100\n",
            "5000/5000 - 20s - loss: 3.5775e-04 - val_loss: 9.9876e-06\n",
            "Epoch 34/100\n",
            "5000/5000 - 21s - loss: 3.5687e-04 - val_loss: 5.8051e-05\n",
            "Epoch 35/100\n",
            "5000/5000 - 21s - loss: 3.5634e-04 - val_loss: 9.2331e-05\n",
            "Epoch 36/100\n",
            "5000/5000 - 21s - loss: 3.5513e-04 - val_loss: 1.1734e-05\n",
            "Epoch 37/100\n",
            "5000/5000 - 21s - loss: 3.5578e-04 - val_loss: 1.9048e-05\n",
            "Epoch 38/100\n",
            "5000/5000 - 21s - loss: 3.5411e-04 - val_loss: 2.4036e-05\n",
            "Epoch 39/100\n",
            "5000/5000 - 20s - loss: 3.5391e-04 - val_loss: 2.4660e-05\n",
            "Epoch 40/100\n",
            "5000/5000 - 21s - loss: 3.5398e-04 - val_loss: 1.1016e-05\n",
            "Epoch 41/100\n",
            "5000/5000 - 21s - loss: 3.5416e-04 - val_loss: 2.2948e-05\n",
            "Epoch 42/100\n",
            "5000/5000 - 21s - loss: 3.5268e-04 - val_loss: 1.3180e-05\n",
            "Epoch 43/100\n",
            "5000/5000 - 21s - loss: 3.5342e-04 - val_loss: 2.9676e-05\n",
            "Epoch 44/100\n",
            "5000/5000 - 21s - loss: 3.5392e-04 - val_loss: 8.1236e-04\n",
            "Epoch 45/100\n",
            "5000/5000 - 21s - loss: 3.5291e-04 - val_loss: 2.4976e-05\n",
            "Epoch 46/100\n",
            "5000/5000 - 21s - loss: 3.5237e-04 - val_loss: 8.1296e-06\n",
            "Epoch 47/100\n",
            "5000/5000 - 21s - loss: 3.5147e-04 - val_loss: 6.6858e-06\n",
            "Epoch 48/100\n",
            "5000/5000 - 21s - loss: 3.5268e-04 - val_loss: 8.7650e-05\n",
            "Epoch 49/100\n",
            "5000/5000 - 21s - loss: 3.5017e-04 - val_loss: 1.6646e-05\n",
            "Epoch 50/100\n",
            "5000/5000 - 21s - loss: 3.4974e-04 - val_loss: 1.9570e-05\n",
            "Epoch 51/100\n",
            "5000/5000 - 21s - loss: 3.5055e-04 - val_loss: 1.5601e-05\n",
            "Epoch 52/100\n",
            "5000/5000 - 21s - loss: 3.4879e-04 - val_loss: 2.6083e-05\n",
            "Epoch 53/100\n",
            "5000/5000 - 21s - loss: 3.5020e-04 - val_loss: 0.0077\n",
            "Epoch 54/100\n",
            "5000/5000 - 21s - loss: 3.4884e-04 - val_loss: 1.0622e-05\n",
            "Epoch 55/100\n",
            "5000/5000 - 21s - loss: 3.4915e-04 - val_loss: 2.6136e-05\n",
            "Epoch 56/100\n",
            "5000/5000 - 21s - loss: 3.4788e-04 - val_loss: 2.5031e-05\n",
            "Epoch 57/100\n",
            "5000/5000 - 21s - loss: 3.4912e-04 - val_loss: 1.1019e-04\n",
            "Epoch 58/100\n",
            "5000/5000 - 21s - loss: 3.4800e-04 - val_loss: 4.3960e-05\n",
            "Epoch 59/100\n",
            "5000/5000 - 21s - loss: 3.4851e-04 - val_loss: 3.0830e-05\n",
            "Epoch 60/100\n",
            "5000/5000 - 21s - loss: 3.4908e-04 - val_loss: 1.1631e-05\n",
            "Epoch 61/100\n",
            "5000/5000 - 21s - loss: 3.4798e-04 - val_loss: 2.2300e-05\n",
            "Epoch 62/100\n",
            "5000/5000 - 21s - loss: 3.4814e-04 - val_loss: 1.2185e-05\n",
            "Epoch 63/100\n",
            "5000/5000 - 21s - loss: 3.4861e-04 - val_loss: 8.3491e-06\n",
            "Epoch 64/100\n",
            "5000/5000 - 21s - loss: 3.4747e-04 - val_loss: 2.3477e-05\n",
            "Epoch 65/100\n",
            "5000/5000 - 21s - loss: 3.4633e-04 - val_loss: 3.0300e-04\n",
            "Epoch 66/100\n",
            "5000/5000 - 21s - loss: 3.4687e-04 - val_loss: 2.4448e-05\n",
            "Epoch 67/100\n",
            "5000/5000 - 21s - loss: 3.4717e-04 - val_loss: 1.4775e-05\n",
            "Epoch 68/100\n",
            "5000/5000 - 21s - loss: 3.4643e-04 - val_loss: 1.1903e-05\n",
            "Epoch 69/100\n",
            "5000/5000 - 21s - loss: 3.4747e-04 - val_loss: 1.1550e-05\n",
            "Epoch 70/100\n",
            "5000/5000 - 21s - loss: 3.4685e-04 - val_loss: 7.3625e-04\n",
            "Epoch 71/100\n",
            "5000/5000 - 21s - loss: 3.4549e-04 - val_loss: 3.9514e-04\n",
            "Epoch 72/100\n",
            "5000/5000 - 21s - loss: 3.4623e-04 - val_loss: 2.1116e-04\n",
            "Epoch 73/100\n",
            "5000/5000 - 21s - loss: 3.4482e-04 - val_loss: 2.3814e-05\n",
            "Epoch 74/100\n",
            "5000/5000 - 21s - loss: 3.4621e-04 - val_loss: 3.8172e-05\n",
            "Epoch 75/100\n",
            "5000/5000 - 21s - loss: 3.4519e-04 - val_loss: 8.3816e-06\n",
            "Epoch 76/100\n",
            "5000/5000 - 21s - loss: 3.4442e-04 - val_loss: 1.4793e-05\n",
            "Epoch 77/100\n",
            "5000/5000 - 21s - loss: 3.4455e-04 - val_loss: 2.4770e-05\n",
            "Epoch 78/100\n",
            "5000/5000 - 21s - loss: 3.4518e-04 - val_loss: 8.1582e-06\n",
            "Epoch 79/100\n",
            "5000/5000 - 21s - loss: 3.4381e-04 - val_loss: 2.3771e-05\n",
            "Epoch 80/100\n",
            "5000/5000 - 21s - loss: 3.4378e-04 - val_loss: 3.3159e-05\n",
            "Epoch 81/100\n",
            "5000/5000 - 21s - loss: 3.4396e-04 - val_loss: 1.6695e-05\n",
            "Epoch 82/100\n",
            "5000/5000 - 21s - loss: 3.4550e-04 - val_loss: 1.5862e-05\n",
            "Epoch 83/100\n",
            "5000/5000 - 21s - loss: 3.4351e-04 - val_loss: 2.6088e-05\n",
            "Epoch 84/100\n",
            "5000/5000 - 21s - loss: 3.4421e-04 - val_loss: 1.6828e-05\n",
            "Epoch 85/100\n",
            "5000/5000 - 21s - loss: 3.4301e-04 - val_loss: 9.0585e-04\n",
            "Epoch 86/100\n",
            "5000/5000 - 21s - loss: 3.4318e-04 - val_loss: 1.7578e-05\n",
            "Epoch 87/100\n",
            "5000/5000 - 21s - loss: 3.4353e-04 - val_loss: 1.6356e-05\n",
            "Epoch 88/100\n",
            "5000/5000 - 21s - loss: 3.4205e-04 - val_loss: 1.9144e-05\n",
            "Epoch 89/100\n",
            "5000/5000 - 21s - loss: 3.4401e-04 - val_loss: 4.7929e-05\n",
            "Epoch 90/100\n",
            "5000/5000 - 22s - loss: 3.4260e-04 - val_loss: 1.0193e-05\n",
            "Epoch 91/100\n",
            "5000/5000 - 22s - loss: 3.4305e-04 - val_loss: 4.6334e-05\n",
            "Epoch 92/100\n",
            "5000/5000 - 21s - loss: 3.4193e-04 - val_loss: 1.3914e-05\n",
            "Epoch 93/100\n",
            "5000/5000 - 21s - loss: 3.4113e-04 - val_loss: 9.9003e-06\n",
            "Epoch 94/100\n",
            "5000/5000 - 21s - loss: 3.4138e-04 - val_loss: 1.7278e-05\n",
            "Epoch 95/100\n",
            "5000/5000 - 21s - loss: 3.4227e-04 - val_loss: 2.6767e-05\n",
            "Epoch 96/100\n",
            "5000/5000 - 22s - loss: 3.4292e-04 - val_loss: 1.0516e-05\n",
            "Epoch 97/100\n",
            "5000/5000 - 22s - loss: 3.4127e-04 - val_loss: 3.9300e-05\n",
            "Epoch 98/100\n",
            "5000/5000 - 21s - loss: 3.3995e-04 - val_loss: 1.7650e-05\n",
            "Epoch 99/100\n",
            "5000/5000 - 22s - loss: 3.4199e-04 - val_loss: 1.1607e-05\n",
            "Epoch 100/100\n",
            "5000/5000 - 21s - loss: 3.4129e-04 - val_loss: 1.1395e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2deZwdVZn3v89des3eaQJJB9JABAMoS4igyAsTGRJwRIfF6OAwI5r5vAIyvm4wM+IyMoOOLzC8wzIocUFlmaASMcqOKEJCiFFCEkgDgXQSSNNZyNbdd3neP05V37q3b3ffJH3vrdx6vp/P/dyqU6eqnlPL+Z3znKVEVTEMwzCiR6zaBhiGYRjVwQTAMAwjopgAGIZhRBQTAMMwjIhiAmAYhhFREtU2YG+YOHGiTps2rdpmGIZhHDA899xzb6lqa7FtB5QATJs2jWXLllXbDMMwjAMGEXltsG3mAjIMw4goJgCGYRgRxQTAMAwjohxQbQCGYRh7SyqVorOzk56enmqbUlYaGhpoa2sjmUyWvI8JgGEYNU1nZyejR49m2rRpiEi1zSkLqkp3dzednZ20t7eXvJ+5gAzDqGl6enpoaWmp2cwfQERoaWnZ61qOCYBhGDVPLWf+PvuSxugJwCu/hbc6qm2FYRhG1YmeANx/OTx1Y7WtMAwjImzbto1bbrllr/c755xz2LZtWxksyhE9AUjvgUxfta0wDCMiDCYA6XR6yP0WL17MuHHjymUWEMVeQNm0+xmGYVSAq666ipdffpnjjz+eZDJJQ0MD48ePZ82aNbz00kt8+MMfZv369fT09HDllVcyf/58IDf1zc6dO5k7dy6nnXYaf/jDH5gyZQr3338/jY2N+21b9AQgYwJgGFHl6798gVUb3x7RY86YPIav/tUxg26/7rrrWLlyJStWrOCJJ57g3HPPZeXKlf3dNRcsWMCECRPYs2cPJ598Mueffz4tLS15x1i7di133XUX3/3ud7nooou47777uPjii/fb9ugJQDblRMAwDKMKzJo1K6+v/k033cTPf/5zANavX8/atWsHCEB7ezvHH388ACeddBLr1q0bEVsiKABWAzCMqDJUSb1SNDc39y8/8cQTPPLIIzz99NM0NTVxxhlnFO3LX19f378cj8fZs2fPiNgSrUZgVRMAwzAqyujRo9mxY0fRbdu3b2f8+PE0NTWxZs0annnmmYraFq0agJ/xmwAYhlEhWlpaeN/73sexxx5LY2MjkyZN6t82Z84cbrvtNt75zndy1FFHccopp1TUtogKQKa6dhiGESl++tOfFg2vr6/n17/+ddFtvp9/4sSJrFy5sj/8C1/4wojZFS0XUCbl/rOp6tphGIYRAqIlAOYCMgzD6McEwDAMI6JESwD6XUDWBmAYhhEtAfB9/1YDMAzDiJoAeCX/jDUCG4ZhREsAMlYDMAyjsuzrdNAAN954I7t37x5hi3JESwCy1gZgGEZlCbMARHQgmNUADMOoDMHpoM866ywOOugg7r33Xnp7e/nIRz7C17/+dXbt2sVFF11EZ2cnmUyGr3zlK7z55pts3LiRM888k4kTJ/L444+PuG3REgB/FlAbCGYY0eTXV8Ebz4/sMQ8+DuZeN+jm4HTQDz30EAsXLmTp0qWoKh/60Id48skn6erqYvLkyfzqV78C3BxBY8eO5frrr+fxxx9n4sSJI2uzR0RdQFYDMAyj8jz00EM89NBDnHDCCZx44omsWbOGtWvXctxxx/Hwww/z5S9/md/97neMHTu2IvaUVAMQkTnAfwJx4Huqel3B9nrgR8BJQDfwUVVdJyItwELgZOAHqnp5YJ+TgB8AjcBi4EpV1f1O0VDYXECGEW2GKKlXAlXl6quv5h/+4R8GbFu+fDmLFy/mX/7lX5g9ezbXXHNN2e0ZtgYgInHgZmAuMAP4mIjMKIh2KbBVVY8EbgC+5YX3AF8Bis1edCvwaWC695uzLwnYK6wXkGEYFSY4HfTZZ5/NggUL2LlzJwAbNmxg8+bNbNy4kaamJi6++GK++MUvsnz58gH7loNSagCzgA5VfQVARO4GzgNWBeKcB3zNW14I/JeIiKruAn4vIkcGDygihwBjVPUZb/1HwIeB4tPijRR+yd8EwDCMChGcDnru3Ll8/OMf59RTTwVg1KhR/PjHP6ajo4MvfvGLxGIxkskkt956KwDz589nzpw5TJ48uWqNwFOA9YH1TuA9g8VR1bSIbAdagLeGOGZnwTGnFIsoIvOB+QCHHnpoCeYOQbANQBVE9u94hmEYJVA4HfSVV16Zt37EEUdw9tlnD9jviiuu4IorriibXaFvBFbV21V1pqrObG1t3b+DBUcAWzuAYRgRpxQB2ABMDay3eWFF44hIAhiLawwe6phtwxxz5Am6fswNZBhGxClFAJ4FpotIu4jUAfOARQVxFgGXeMsXAI8N1aNHVTcBb4vIKSIiwN8C9++19XuLCYBhRJJydzAMA/uSxmHbADyf/uXAg7huoAtU9QUR+QawTFUXAXcAd4pIB7AFJxIAiMg6YAxQJyIfBv5SVVcBnyHXDfTXlLsBGApcQCYAhhEFGhoa6O7upqWlBanRdj9Vpbu7m4aGhr3ar6RxAKq6GNdXPxh2TWC5B7hwkH2nDRK+DDi2VENHBKsBGEbkaGtro7Ozk66urmqbUlYaGhpoa2sbPmKAaE0FYQJgGJEjmUzS3t5ebTNCSeh7AY0o5gIyDMPoJ1oCYDUAwzCMfiImADYOwDAMwydaApAJlPrts5CGYUScaAmAuYAMwzD6iZgAWCOwYRiGT7QEwOYCMgzD6CdaAhDM9K0GYBhGxImYAKSKLxuGYUSQaAmADQQzDMPoJ1oCYC4gwzCMfiImANYIbBiG4RMtAQi6gGwgmGEYESdaAmADwQzDMPqJngDE63PLhmEYESZaApBJQdL7Yo61ARiGEXGiJQDZNCQac8uGYRgRJnoC0F8DsEZgwzCiTbQEIJOChC8AVgMwDCPaREsAsmlI+i4gawMwDCPaREwAUtYGYBiG4RExAchAwrqBGoZhQNQEIJPKuYBsJLBhGBEnWgKQDTYCWxuAYRjRJmICkPZcQGIuIMMwIk9JAiAic0TkRRHpEJGrimyvF5F7vO1LRGRaYNvVXviLInJ2IPxzIvKCiKwUkbtEpGEkEjQkmTTEEu5nAmAYRsQZVgBEJA7cDMwFZgAfE5EZBdEuBbaq6pHADcC3vH1nAPOAY4A5wC0iEheRKcBngZmqeiwQ9+KVl2zKBMAwDMOjlBrALKBDVV9R1T7gbuC8gjjnAT/0lhcCs0VEvPC7VbVXVV8FOrzjASSARhFJAE3Axv1LSglk0xBPmgAYhmFQmgBMAdYH1ju9sKJxVDUNbAdaBttXVTcA3wFeBzYB21X1oWInF5H5IrJMRJZ1dXWVYO4QZNIQS0IsbgJgGEbkqUojsIiMx9UO2oHJQLOIXFwsrqrerqozVXVma2vr/p04m3KZfzxpAmAYRuQpRQA2AFMD621eWNE4nktnLNA9xL4fAF5V1S5VTQE/A967LwnYK8wFZBiG0U8pAvAsMF1E2kWkDtdYu6ggziLgEm/5AuAxVVUvfJ7XS6gdmA4sxbl+ThGRJq+tYDawev+TMwSqLtOPeQKQMQEwKsSerZDNVtsKwxjAsALg+fQvBx7EZdL3quoLIvINEfmQF+0OoEVEOoD/A1zl7fsCcC+wCvgNcJmqZlR1Ca6xeDnwvGfH7SOaskL8En8sYW0ARuXo3QHXz4A1v6y2JYYxgEQpkVR1MbC4IOyawHIPcOEg+14LXFsk/KvAV/fG2P3Cz/Dj1g3UqCA92yG1G97eVG1LDGMA0RkJ7M/9E0u6nwmAUQkyffn/hhEioiMAeS6ghM0FZFQGv+BhAmCEkOgJQNxvA7DZQI0K0F8DsOfNCB/REYA8F5C1ARgVwn/urMBhhJDoCID/AsYSNhDMqBzmAjJCTIQEwPP59w8EszYAowKYC8gIMdERgEygBmDjAIxKYb2AjBATHQEIuoBiCSuRGZXBXEBGiImQAPi9gKwR2Kgg5gIyQkx0BCBj4wCMKuDXPE0AjBASHQEodAFZDcCoBOYCMkJMhATAXEBGFTAXkBFioiMAmcIagL2QRgWwXkBGiImOAPg+/5iNAzAqSMbaAIzwEiEB8F7AeML9zAVkVAK/5G81TiOEREcABriATACMCmCNwEaIiY4A9E8HbY3ARgUxF5ARYqInAP4XweybwEYlsEZgI8RERwBsLiCjGpgAGCEmOgKQ5wKy6aCNCmEuICPERE8A/IFgmgHV6tpk1D42EMwIMdERgH4XUNwJAFgtwCg/WesFZISX6AhAngsonh9mGOXCXEBGiImQAPgDwZLuByYARvmxRmAjxERHAAqngwYTAKP8BD8Kb21ORsiIjgBk04AUtAHYfEBGmQmW/M0NZISMkgRAROaIyIsi0iEiVxXZXi8i93jbl4jItMC2q73wF0Xk7ED4OBFZKCJrRGS1iJw6EgkalGwq5/rx2wDshTTKTVAAbD4gI2QMKwAiEgduBuYCM4CPiciMgmiXAltV9UjgBuBb3r4zgHnAMcAc4BbveAD/CfxGVY8G3g2s3v/kDEEmlSv5mwvIqBTBEefWDmCEjFJqALOADlV9RVX7gLuB8wrinAf80FteCMwWEfHC71bVXlV9FegAZonIWOB04A4AVe1T1W37n5whyGZcDyDI/ZsAGOXGXEBGiClFAKYA6wPrnV5Y0Tiqmga2Ay1D7NsOdAHfF5E/isj3RKS52MlFZL6ILBORZV1dXSWYOwjZVM71Y20ARqXIEwCrARjholqNwAngROBWVT0B2AUMaFsAUNXbVXWmqs5sbW3d9zNmirQBWA3AKDfBUr8JgBEyShGADcDUwHqbF1Y0jogkgLFA9xD7dgKdqrrEC1+IE4TykecC8msAViU3ykxeDcAKHEa4KEUAngWmi0i7iNThGnUXFcRZBFziLV8APKaq6oXP83oJtQPTgaWq+gawXkSO8vaZDazaz7QMTVEXkL2QRpnJ9EGyKbdsGCEiMVwEVU2LyOXAg0AcWKCqL4jIN4BlqroI15h7p4h0AFtwIoEX715c5p4GLlNV3/F+BfATT1ReAf5+hNOWT9AF1D8S2NoAjDKTTUNdM6R2mwAYoWNYAQBQ1cXA4oKwawLLPcCFg+x7LXBtkfAVwMy9MXa/yKYDLiBrAzAqRKbPCcCuLusFZISOaI0EtnEARqXJ9EGyObdsGCEiOgKQSbnPQUJOAKxEZpSbTArqrA3ACCfREYA8F5C1ARgVwncBgdU4jdARMQHwawDWBmBUAFWvEXiUW7cagBEyoiMAxVxAJgBGOfFdjHXWBmCEk+gIQJ4LyAaCGRXAz/D7BcCeNyNcREgAis0Gam0ARhnxBcAGghkhJUICkAkMBDMXkFEBzAVkhJzoCIB9D8CoNANcQPa8GeEiOgJQ1AVkL6RRRrJWAzDCTYQEIB2YDtoGghkVoN8FZN1AjXASHQHIFJsKwhqBjTIyoBHYChxGuIiOAJgLyKg0vgDE69wzZzUAI2RESACKuIBMAIxy4pf440knAjbuxAgZ0RGATLGBYCYARhkJ1gDiSXMBGaEjOgJgXwQzKk1/DaDO/cwFZISMCAlA0AUUA4mZABjlJegCiiVNAIzQEQ0B8GdljAU+gBZLmAAY5cVcQEbIiYYA+Bm93wYAJgBG+ekXgKS5gIxQEi0BiBfWAGwcgFFGCnsBWQ3ACBnREAD/xctzAcXthTTKi7mAjJATDQEo6gJKmgvIKC9Z6wVkhJtoCcAAF5AJgFFG8lxAVgMwwkc0BKCoC8jaAIwyM8AFZDUAI1xEQwD8qnieCyhuQ/ON8uJn+DGbCsIIJxERAK+kH7duoEYFsV5ARsgpSQBEZI6IvCgiHSJyVZHt9SJyj7d9iYhMC2y72gt/UUTOLtgvLiJ/FJEH9jchQ9LvAornwuLWCGyUmUyfK/2LmAvICCXDCoCIxIGbgbnADOBjIjKjINqlwFZVPRK4AfiWt+8MYB5wDDAHuMU7ns+VwOr9TcSwDOoCsjYAo4xkUq7kDzYVhBFKSqkBzAI6VPUVVe0D7gbOK4hzHvBDb3khMFtExAu/W1V7VfVVoMM7HiLSBpwLfG//kzEM/b2AzAVkVJBMKvfMmQvICCGlCMAUYH1gvdMLKxpHVdPAdqBlmH1vBL4EZIc6uYjMF5FlIrKsq6urBHOL4H+Mu7AXkL2QRjnJ9OVqAOYCMkJIVRqBReSDwGZVfW64uKp6u6rOVNWZra2t+3bC7GDdQK0GYJQRqwEYIacUAdgATA2st3lhReOISAIYC3QPse/7gA+JyDqcS+kvROTH+2B/aQzqArI2AKOMZPoCAmADwYzwUYoAPAtMF5F2EanDNeouKoizCLjEW74AeExV1Quf5/USagemA0tV9WpVbVPVad7xHlPVi0cgPcUZdCCY1QCMMpLnArKpIIzwkRgugqqmReRy4EEgDixQ1RdE5BvAMlVdBNwB3CkiHcAWXKaOF+9eYBWQBi5T1coXu206aKMaZNP5bQDZlPs2hUh17TIMj2EFAEBVFwOLC8KuCSz3ABcOsu+1wLVDHPsJ4IlS7NhnBp0LyKrkRhkpdAGBq40m6qpnk2EEiMZI4GIuoLi1ARhlptAF5IcZRkiIhgCYC8ioBplU7pnzBcBqnUaIiJgABAYhmwAY5WYwF5BhhIRoCEBwUi4fEwCj3ARdQH5NwFxARoiIhgAUdQHFcyOEDaMcZNL5A8HABMAIFRETgGAvIJsN1CgzhVNBgLmAjFBR8wKgqtz8qDfhqH0S0qgkRXsBmQAY4aHmBUBESPUFvszkY1NBGOUmk8oVOswFZISQmhcAgNH+uJs8F1DcagBGecmrAXjPntUAjBARCQEY5Rf8B/QCspfRKCPZlA0EM0JNZAQgi9gnIY3KUjgdNJgAGKEiIgKgZIjnB8YSoFnIDvk9GsPYd6wXkBFyIiEAzQklpXEyWc0F+rWBKkxOakSAbLZgNlCbCsIIH5EQgMaEkibO9j2Bly9mjXJGGSn8Cp25gIwQEgkBaIoraWJs2RV4+fwuodYOYJQDP6PvnwrCChxG+IiEADTEs6RJFAiA90KaABjloH/+KesFZISXaAhATEkRZ8uu3lyg3wZgg8GMclA4AaEJgBFCIiEA9bEsGY2xZVeRNgCrARjloNAFZL2AjBASEQHIkCJRUAPwBcBeSKMMDBAAmwvICB+REIC4ZshKPL8GELdGYKOM9LuA/F5A9j0AI3xEQgDIpiE2WA3A2gCMMjCgF5C5gIzwEQ0B8Ibkd+f1AvIbga0GYJSBbEEvoFjMFTqsBmCEiGgIQDaNxBJs3W3dQI0KUewzpPE6EwAjVERHABJJtuwsIgBWJTfKQaELCGwCQiN0REMAMili8SRbdhcbCWxtAEYZyBT5CJHVAIyQEQ0ByKaJJ5L0pLLs7vO/D2xtAEYZKeYCiiVNAIxQUZIAiMgcEXlRRDpE5Koi2+tF5B5v+xIRmRbYdrUX/qKInO2FTRWRx0VklYi8ICJXjlSCipJNkUi6qni37wayNgCjnAzmAjKXoxEihhUAEYkDNwNzgRnAx0RkRkG0S4GtqnokcAPwLW/fGcA84BhgDnCLd7w08HlVnQGcAlxW5JgjRzbTLwD9DcEmAEY5KZwLyF+2GoARIkqpAcwCOlT1FVXtA+4GziuIcx7wQ295ITBbRMQLv1tVe1X1VaADmKWqm1R1OYCq7gBWA1P2PzmDkEmR9GsAfldQGwhmlJNBewFZDcAID6UIwBRgfWC9k4GZdX8cVU0D24GWUvb13EUnAEuKnVxE5ovIMhFZ1tXVVYK5RcjmBGCrLwDWBmCUE3MBGQcAVW0EFpFRwH3AP6rq28XiqOrtqjpTVWe2trbu24myaerq6wFyU0KbC8goJ5mCmqa/bC4gI0SUIgAbgKmB9TYvrGgcEUkAY4HuofYVkSQu8/+Jqv5sX4wvmUyaZCJJIiY5F5AJgFFOzAVkHACUIgDPAtNFpF1E6nCNuosK4iwCLvGWLwAeU1X1wud5vYTagenAUq994A5gtapePxIJGZJsCoknGd9cF3AB+QPBTACMMjCoC8hqAEZ4SAwXQVXTInI58CAQBxao6gsi8g1gmaouwmXmd4pIB7AFJxJ48e4FVuF6/lymqhkROQ34BPC8iKzwTvVPqrp4pBMIeB/nTtLSXGc1AKMyFM4F5C9ntlXHHsMowrACAOBlzIsLwq4JLPcAFw6y77XAtQVhvwdkb43dZzJuNtDxTUVqACYARjnIFHwUHpwA2PNmhIhojASOJyHRwIRRddYIbFSGTJ/L8CVQzrHZQI2QUVIN4IDny68C0HL/ytx8QCYARjnJpPLnAQIbCGaEjmjUADzGN9WxbXeKdCZr4wCM8pLpy+8BBNYLyAgdkRKAllH+dBApGwlslBffBRTEegEZISNSAjC+KTAfkLmAjHKSSRcRAHMBGeEiUgLQ0hyYEdQEwCgnRV1ASRt3YoSKSAnAhFHFagD2QRijDJgLyDgAiJYANAVmBBUBiVujnFEeMqnijcDZFKhWxybDKCBSAjDecwFtCX4UZjgX0Gt/gKdvLrNlRs0xmAsIrNBhhIZICUAyHmN0Q4LuXb0uoBQBWHIbPHwNpK3qbuwFRV1AdblthhECIiUAAO9qG8sv/7SR7p29ngAM0wbQ9ZITiS2vVMZAozbIDtILCEwAjNAQOQH42l8dw87eNP/6wCo3GGyoGkAmBd0dbrlrdWUMNGqDYi4g63lmhIzICcD0SaP532ccyS9WbKRX47lZG4ux5dXc9q4XK2OgURuYCyh8vL4EXn682laEisgJAMBlZx7BEa3NbOvJkkoNIQBveZm+xGGz1QCMvSCTyp8JFEwAqs1vroJfXlltK0JFJAWgPhHnuvPfRV82xp9ef4tsdpBueV1r3P9h780tGwc+D30FHvl6ec8x2DgAsF5A1SCTgjdfgG2vwe4t1bYmNERSAABOnjaBUU0NdHbv4Ev3/ZlMMRHoegnGToW2ma4twF7cAx9V+OOd7lfO/viZVO26gFbdD68+WW0r9o6uNZDxev+98efq2hIiIisAAONGNTJjUjMLn+vks3f9kb50Nj9C1xqY+A5ofadruOt+uTqGGiNHdwfs2Qq7umDruvKdZ7CBYP62A5Vs1rlRFl4KfbuqbU3pbFxRfDniRFoAJJbkHRPr+edz3smvnt/EJ3/wbO6DMdksvLUWWo+Gg452YeYGOvBZvyS33Pls+c5T1AXkf4f6ABaArtWegG6Gpd+ttjWls+lPUDfK1eg3mQD4RFoAmNAOrz3Fp2e18O0L3sXSdVs496bfsfz1rbD9dUjvgdZ3QMt0QEwAaoH1S6FhnMsM1i8t33lq1QX02h/c/8HHwVM3Qs/b1bWnVDatgIPfBZOPd2JgAFEXgP/1JVeaeeomLpo5lZ/97/eSiAsX3fY0ix7xuou1Hg11TTB+mvUEqgXWL4W2k2HKidBZTgHoy5X4fWpCAJ6CMW3wVze5d2fJbdW2aHgyaXhjpcv8DzneDers2V5tq0JBtAXgkHfDsefDM7fAjjc4dspYHrji/Zw1YxLPr3CZwxef6OHXz29i55gjyVoN4MBmzzbnwpj6Hmib5TKFcvmxa7EXkKqrARz2XiegR38Q/vD/wt+r5q2XXG3+EE8AwGoBHtH4JvBQnPnPrlfDb78NH7yesY1Jbr34JLbf/d/s7JjAw+v6+J9Vy/lSopFPxddy+jd/Q3NjA6MakoyuT9BYF6cx6X71yRgNyTj1iRiJWIxEXIjHhGQ8Rl3c/cdiQkyEmNC/LRFz8WIxIS5uu4ibsDQmbls8sC0WIxcHdyz37XE/DEQEgbzj+ttwUfuJSc4m8f5jBXZAfqeZYPxcWP566NiwzP1PPRnSvaAZ2LAc2t8/sufJZt2xa80FtOUV2PmmEwCAM/8J1vwKfvd/4exrq2vbUPg+/0PeDc0TvbA/Qfvp1bMpJJgAtBwBJ/0dPPcDOPUytw6M3fkKtB3Dkotns3rTDjIrXqfuuUVcOK2Xl6WVHT1pdvameWtnLz2pDHtSGXrTWXq8/yjP+FsoQr5Q5SKQF+7HzwmOoKr4lzAWEKV8ffFXCi92TmBVQVFU4dOZu/kkMc78yQ6SpHkUuOXHd/GjeF+ezf1pEJeXA6gq8bgnwjHJi6uq/fdbBOpJsxhY8PQG7lr+W7KqiAjTsq/zPeDfHnieJx8aF7hezl5nqzueH+5fp8JtQQqvix83eJVisWBhQRAURAbEDe5TeN6zeh7kCuAzTzWyaelTxET4TONfMvvp/+K2lcLDTed49uRsV4Wsdy8H3POC58K/T7n7nl8Q8dNWGD+T9a6/QNwrMPnbAT6x7UHOlHo+vWgLxN7mhngrL/3+UW5ZPWvAdfRtz2TV2a25gph/PXL3zQv30yWS90S6uJp3Df3dc8+7EI/l38NMVslk/aO48LGNSb5z4buL3Kn9wwQA4PQvwYqfugFC837iwrpehHddRH0izvFTx0H8VHgOPn+CwjEnDXvIbFZJZ5VMVunLZOlLZ0llsv0PVcbbns5mSWdcvIwq2aySVfew+P8ZdXFV3YOR9eL5D5n/gvmZg/+QZlX7H+RMNvdC5L9ELiDrv0jecfxl316f4EsQHDvhZ7S+zcGMN5jB+OEUZGhuP/98OqAm4aclz+4AwdjqXf9MVvMynDNeXceb6cM57ahpqELXmqmcUb+OdYdNDFyzfPv8lzzvngYSpeiAFz+Z3gU7YMyoJqZPGNWfybX0joWdcPCoGIeNbgpcD3fs4plILhPKr+EFM2e8a5Z/RYKZpnue3D2d2ruWK7u+xh0T/pGVDTPzzhk8r4+fOZ2wZzVvx8axc1Q7o7zj/mD8FYzPbmX+jv8im2jkqebZ/fcxq14t18+QlbznIpsFJVu0cODfi0w2O2CMTrFaZyzmjp3OZulN5wvoYb0v8WricN7uVZQUHfEjOLT3JXb0pPOvEbnrFBR69Z8LVWdbYKes5t6RwuuWVwAKPEe5Y3rvpXdOP5n+uf1CQVaVnU0FtckRwgQAYPQkOOMqN+3zsgVw1Fzofds1APtMfAd70xMoFrLRjX8AAAzfSURBVBPqvAe/kXgZjDb2imwGrlsD77qIf/vgcS7sF6fT+tJv+Pb576Ig99w/dm+Bb8MFsw7ngvcECgvbWuFG+OQpU/jkiTNH7nx7QyYN3/08ZDbz5b5b4VPPQP2o0va98UU49HR+9NH35Ienfgk/vZDPrPsOnznrWJhx3sjbva9kM/Dv6+CET/CLc97nwn47Gx6/ll9cehw0jKmmdVUn2o3AQU69Ao78APzmanh+oQub+I7c9romGH+YdQXdW9Y+An/8cfW/gtW1Bvp2wNRAtb/tZNjdPfJTfWcCHxwKEoY2gCW3uZGw770Ctq+HJ/69tP22rYdtr8Nh7xu4LdkA8+5y13PhpdDxyMjavD90d0Bqt+sB5OM3BL/xfHVsChElCYCIzBGRF0WkQ0SuKrK9XkTu8bYvEZFpgW1Xe+EvisjZpR6z4sRi8JH/hqYWVxOA/BoAuBHBm1dXNjPLpGDDc/DMbfDCz3NO6bCTzcJj18JPzof7L4MHPlf8g+jpPtj0Zze1QDm/z+wPAAsKgL883HiAvl1uWpBS77ufwe9LL6DdW+DJ/4Df/gdsfa2085XK1tfg8WvhHXPgrH+FmZ90PeA2/nH4fV9/2v1PKyIA4GoRH7/XDZq8+2J47emRs3t/2BhoAPbxl21A2PAuIBGJAzcDZwGdwLMiskhVVwWiXQpsVdUjRWQe8C3goyIyA5gHHANMBh4REb9YPdwxK0/zRLjgDvjBB6F+NIw6KH/7wcfBS7+GG45xtYXDz3CNxuMOhcbxuXjZDOzY5EpNb29w7qTeHZDqgQmHu+NMnA4Sg76drk9yLOmqo4kG2LzKlaI6HnWZU3pP7tiTjoXZ18D0v8y5LXa8Cet+B6/+1r3kza0w+mAYMwUmzYBJx0Fzi4ur6uyTmBO9dJ/rGrlxhesuN/pgmHiUs69hrCvFxuvcLzZIeSG1B3ZudhmfeM7YB/8J1j4Ix1/srutTN8L2TvjwLa4HxsuPuS6Fm1flMswJh7uG+OP/BpKNTjBSu932dI/79x3JIs6+hnG5/vapPa6rZzzp7l+i3mW2u7rcNMBNE2F8e87u1qOhbjSs+z0c+9cufpBdb8HS291vz1Y46BiY+fdw3AWQaHTTg2jWnS9el7ufb290+w8qAH3eaNq3nH0Sc8f68z3w7B2Q2gUIPP5N11PliNmuYNI0AZoPgjGTYdQkl+5sxj1f6T6X5mTjQHeWqrNr8Rfccc/5josz+6uuF8+iz7rMu3401DUXd4e99pS73gfNKP4MADSOg4t/Dt+fAz+9CC74vrumu99ydrYe5QZVJhvybUvtdgPK0ntcOuvH5Gzo2+3un/8O9e1ydow6yF2LREMubmpPLp7EXHo2LHP3auJRuXOOngSjD3HCl0nn9s+m3a9nu2sD7HrR2T7pWFe7GTMZtr7qeo51v+wGkk461r0rhdN+gDt2346c3ckmZ3ey0eUF3Wtz08yPOwzGTXXvbqxyLmMp1qsgL4LIqcDXVPVsb/1qAFX990CcB704T4tIAngDaAWuCsb143m7DXnMYsycOVOXLVu2l0ncB5bf6W78aZ/LD+/bBSvvg7UPuwylb0duW6LR/WvW+/D3MCX1eL3rKlj4cRCJ5fY96BiXARzq9Vt//Wl47JvuIWwc7+JlUu4FAvditEx3tu94M184Gsa5c6X2uPMOZpM/YVYxJJ4TAz/T69vpXrpCYgmYcx2c/Cn3gi37Pvzq87lzx+tdCXzKibkS2dM3u9pOvB7QEl0l4oQz1TPQ9nhd/jHe+SH46J35ce78a3j5UbfcON5dQ4m7+7B9vROeo86FaafBn+/eu/7j8+6Co8/Jrad74ZsHDR5fYm5cyvs/7zLiP90DK37i7nexuMnm/GcQ3HWva3bXMJ4ExLm5/Gfh7H9zIuvzws/hf/4u/7jxOnecmHcdwGViR34APn7P8One3gkL5rjrV8zuUQfnRD21e+C7kmh096JnuyeG+0nbyfCpArfUT+e5wtyw+E22OLFJ9wyMEku4zD2edMvp3lzBpRj1Y9x7M1geEUs6kYglcuLU3AqXLSkef7gUiDynqkUbnUoRgAuAOar6KW/9E8B7VPXyQJyVXpxOb/1l4D24zP4ZVf2xF34H4F/1IY8ZOPZ8YD7AoYceetJrr41wtXhfSfe50uu2190Uszve8Jr74+5BGDPZ1QzGtLmSkf9Sdq91Lo/Nq9wNbhznMp1s2r1kvTvcqOMjZsPYKQPPm0m5TGHjCle6iiddSaj9/W6ou196UHUlzDdXut/Wde78yYZcBpvNOJtbj3J+0fHt0LPN1QTeWusEL5tyD3Im7f335i8nm12pZtRB7sX1Re2Qd7uaTpBXn3S/w94Lh57qHvIg/kCjNb9y6Uo2uTiJBkjUObsllusC07PdZW57trg4fgbul4p7386379BTXSk6yLb1rjay803369nuXkzNupfu5E+76UB8Nix38UW8F9QrvWdS7r9ulLOhuRWmnzWwZPj0za621Nzqfok6z7WkMPkEVwsqvCZ9O51raM8Wt+/bG92vd4dXCxrrztO305Wk+3Y6ezIpd9ymCe5c49vd4K1gTU7V1Ry3vJJ7/jJ97hr6+/t5xPEfgynD94ADnJ2vPQWNE1wNUNV9X2Pzati+wT27/v2tH52r/e7udu/Snq2u0NI80dneMDZXQ+nZ7t2vzblaIer2bxgD9WPd/fNL3+2nD7R78xpY84BXo/Qy4njCvb91ze6daD3anfeNla4mseUVFzblRFfQ2rrOvVtda1zBKtPnrll/2pqczb7dfbtydjeOc+eYeFSusLHtdXef03tcgSb4saq6UXDW10u79gUc0AIQpGI1AMMwjBphKAEopRF4AzA1sN7mhRWN47mAxgLdQ+xbyjENwzCMMlKKADwLTBeRdhGpwzXqLiqIswi4xFu+AHhMXdViETDP6yXUDkwHlpZ4TMMwDKOMDNsLSFXTInI58CAQBxao6gsi8g1gmaouAu4A7hSRDmALLkPHi3cvsApIA5epulbAYscc+eQZhmEYgzFsG0CYsDYAwzCMvWN/2wAMwzCMGsQEwDAMI6KYABiGYUQUEwDDMIyIckA1AotIF7CvQ4EnAm+NoDkHAlFMM0Qz3VFMM0Qz3Xub5sNUtbXYhgNKAPYHEVk2WEt4rRLFNEM00x3FNEM00z2SaTYXkGEYRkQxATAMw4goURKA26ttQBWIYpohmumOYpohmukesTRHpg3AMAzDyCdKNQDDMAwjgAmAYRhGRKl5AQjdx+fLhIhMFZHHRWSViLwgIld64RNE5GERWev9jx/uWAcaIhIXkT+KyAPeeruILPHu+T3elOM1hYiME5GFIrJGRFaLyKm1fq9F5HPes71SRO4SkYZavNciskBENnsf2vLDit5bcdzkpf/PInLi3pyrpgUg8EH7ucAM4GPeh+prkTTweVWdAZwCXOal9SrgUVWdDjzqrdcaVwKrA+vfAm5Q1SOBrcClVbGqvPwn8BtVPRp4Ny79NXuvRWQK8Flgpqoei5tGfh61ea9/AMwpCBvs3s7FfWdlOu7TubfuzYlqWgCAWUCHqr6iqn3A3cB5VbapLKjqJlVd7i3vwGUIU3Dp/aEX7YfAh6tjYXkQkTbgXOB73roAfwEs9KLUYprHAqfjvsOBqvap6jZq/F7jvl/S6H11sAnYRA3ea1V9EvddlSCD3dvzgB+p4xlgnIgcUuq5al0ApgDrA+udXlhNIyLTgBOAJcAkVd3kbXoDmFQls8rFjcCXAO/L3rQA21Q17a3X4j1vB7qA73uur++JSDM1fK9VdQPwHeB1XMa/HXiO2r/XPoPd2/3K42pdACKHiIwC7gP+UVXfDm7zPtNZM/1+ReSDwGZVfa7atlSYBHAicKuqngDsosDdU4P3ejyutNsOTAaaGegmiQQjeW9rXQAi9fF5EUniMv+fqOrPvOA3/Sqh97+5WvaVgfcBHxKRdTj33l/gfOPjPDcB1OY97wQ6VXWJt74QJwi1fK8/ALyqql2qmgJ+hrv/tX6vfQa7t/uVx9W6AETm4/Oe7/sOYLWqXh/YtAi4xFu+BLi/0raVC1W9WlXbVHUa7t4+pqp/AzwOXOBFq6k0A6jqG8B6ETnKC5qN++52zd5rnOvnFBFp8p51P801fa8DDHZvFwF/6/UGOgXYHnAVDY+q1vQPOAd4CXgZ+Odq21PGdJ6Gqxb+GVjh/c7B+cQfBdYCjwATqm1rmdJ/BvCAt3w4sBToAP4HqK+2fWVI7/HAMu9+/wIYX+v3Gvg6sAZYCdwJ1NfivQbuwrVzpHC1vUsHu7eA4Ho6vgw8j+slVfK5bCoIwzCMiFLrLiDDMAxjEEwADMMwIooJgGEYRkQxATAMw4goJgCGYRgRxQTAMAwjopgAGIZhRJT/D3NobvOmN7hVAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(98114, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qG7WwS1XEqx2"
      },
      "source": [
        "# Pivot Point Matrix(P):\r\n",
        "This is a graph matrix of K Nearest Neighbors which act as the pivot points for the rest of the calculation for approximation of the matrix through Nystrom Method .This is created by the brute force method from the points sampled out from the large dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVb_OA-PJZBH"
      },
      "source": [
        "import random\r\n",
        "from sklearn.neighbors import kneighbors_graph\r\n",
        "\r\n",
        "idx = list(range(0, X.shape[0]))\r\n",
        "rand_idx = random.sample(idx, 9400)\r\n",
        "for i in rand_idx:\r\n",
        "  idx.remove(i)\r\n",
        "\r\n",
        "rand_X = []\r\n",
        "for i in rand_idx:\r\n",
        "  rand_X.append(X[i])\r\n",
        "\r\n",
        "P = kneighbors_graph(rand_X, n_neighbors=5).toarray()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Clj5s2VaHzIp",
        "outputId": "9aad13d9-39af-4605-ba6d-36e311aa4b11"
      },
      "source": [
        "P. shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9400, 9400)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o60akhwEIPQj"
      },
      "source": [
        "#Reference Point Matrix(R & R'):\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z55LBJw0DvLt"
      },
      "source": [
        "import numpy as np\r\n",
        "from scipy.spatial import distance \r\n",
        "\r\n",
        "k = 9401\r\n",
        "R = np.zeros((9400,88714))\r\n",
        "R.shape\r\n",
        "\r\n",
        "for i in rand_idx:\r\n",
        "  for j in idx:\r\n",
        "    if distance.euclidean(X[i], X[j]) < 5:\r\n",
        "      R[i][k] = 1\r\n",
        "    else:\r\n",
        "      R[i][j] = 0\r\n",
        "    k += 1\r\n",
        "\r\n",
        "RT = numpy.transpose(R)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouFNRXxTGU1T"
      },
      "source": [
        "#Resultant Matrix(A):\r\n",
        "Here we create the resultant matrix which would be used as the affinity matrix in the calculation of graph laplacian for eigen value decomposition."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQprmDKDGUlj"
      },
      "source": [
        "P_inv = np.linalg.inv(P)\r\n",
        "A = RT* P_inv* R"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QivK8VgIp7c"
      },
      "source": [
        "#Diagnol Matrix(D):\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f18fxxTjIjgJ"
      },
      "source": [
        "D = np.diag(A.sum(axis=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJI4N9LLHbRy"
      },
      "source": [
        "#Laplacian Matrix(L):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rR_DacoTHbnK"
      },
      "source": [
        "# calculated the laplacian matrix by taking the difference between the diagnol matrix and the affinity matrix \r\n",
        "L = D-A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-vffxtiGQvd"
      },
      "source": [
        "#Spectral Clustering:\r\n",
        "Here we use the above created Laplacian matrix .."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8CLem7EGQgj"
      },
      "source": [
        "# find the eigenvalues and eigenvectors\r\n",
        "vals, vecs = np.linalg.eig(L)\r\n",
        "\r\n",
        "# sort\r\n",
        "vecs = vecs[:,np.argsort(vals)]\r\n",
        "vals = vals[np.argsort(vals)]\r\n",
        "\r\n",
        "# kmeans on first three vectors with nonzero eigenvalues\r\n",
        "kmeans = KMeans(n_clusters=4)\r\n",
        "kmeans.fit(vecs[:,1:4])\r\n",
        "clusters = kmeans.labels_"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}